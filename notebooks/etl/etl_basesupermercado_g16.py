# -*- coding: utf-8 -*-
"""ETL_basesupermercado_G16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RAiOQhy4D9O6HEWEqPbHBsC5IiLp6U2Q

# **Data Preparation**

Tomando como base el archivo "base supermercado", analizaremos cada tabla, corregiremos errores y transformaremos aplicando las 3 formas normales.

##Importamos librerías y la Base de Datos de Supermercado
"""

from google.colab import files
from google.colab import drive

drive.mount('/content/drive')

"""Librerías que vamos a utilizar"""

import pandas as pd
import datetime as datetime
import numpy as np

"""#Tabla Maestro Sucursales:

Contiene 433 registros de sucursales, y 15 columnas de datos.

Columna  | Nombre  | Descripción
----------  | ---------|------------------
0  | idSucursal       | contiene datos int, PK de la tabla
1	|fechaAlta       | datetime, sin nulos, fecha de alta de cada sucursal
2	|nombre       | nombre de cada sucursal, contiene un nulo, string
3	|direccion       |  calle y número en algunos, contiene algunos nulos, string
4	|localidad       | string, contiene nulos, ciudad de la sucursal
5	|provincia       | string, contiene nulos, ciudad de la sucursal
6	|horarioLunes       | rango horario del día de la sucursal
7	|horarioMartes       | rango horario del día de la sucursal
8	|horarioMiercoles       | rango horario del día de la sucursal
9	|horarioJueves       | rango horario del día de la sucursal
10	|horarioViernes       | rango horario del día de la sucursal
11	|horarioSabado       | rango horario del día de la sucursal
12	|horarioDomingo       | rango horario del día de la sucursal
13	|fechaBaja       | fecha de baja de la sucursal, sin dato
14	|estado       | estado de la sucursal, sin dato

##Importar tabla
"""

bs_maestro_suc = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='Maestro SUCURSALES')
bs_maestro_suc.shape

bs_maestro_suc.head()

bs_maestro_suc.info()

"""##Control de Maestro Sucursales

###Campo idSucursales
"""

bs_maestro_suc['idSucursal'].value_counts()

"""Contando los valores de idSucursal comprobamos que ninguno se repite, falta verificar que los valores sean entre 1 y 433."""

ls_idsuc = bs_maestro_suc['idSucursal'] #convertimos en lista los idSucursal

id_sucursalesfiltradas = [num for num in ls_idsuc if 1 <= num <= 433]
id_sucursalesfiltradas_n = [num for num in ls_idsuc if 1 > num > 433]

print("Números dentro del rango:", id_sucursalesfiltradas)
print("Números fuera del rango:", id_sucursalesfiltradas_n)

"""Ninguno de los números de idSucursal esta fuera del rango, ni repetido, pueden ser utilizados como PK

###Campo Fecha Alta
"""

bs_maestro_suc['fechaAlta'].head()

"""Las fechas estan en formato  datetime64[ns], donde podrían también tener cargada la hora, para el análisis no es significativo."""

años = bs_maestro_suc['fechaAlta'].dt.year
años.value_counts()

"""Este paso nos muestra la cantidad de sucursales por año de alta, no hay evidencia de errores con las fechas de altas.

###Campo Nombre
"""

bs_maestro_suc['nombre'].head()

bs_maestro_suc[bs_maestro_suc['nombre'].isna()]

"""La sucursal con id 235 no tenemos datos de nombre, dirección, localidad ni provincia, solo los horarios de apertura"""

bs_maestro_suc[(bs_maestro_suc['idSucursal']>225) & (bs_maestro_suc['idSucursal']<245)]

"""No hay un orden de idSucursal para poder asignarle un nombre a la sucursal y estimar una dirección.

### Campo Dirección
"""

bs_maestro_suc['direccion'].head()

bs_maestro_suc['direccion'].value_counts()

bs_maestro_suc[bs_maestro_suc['direccion'].isna()]

"""Son dos las sucursales que no continen dirección

Detectamos que hay varias direcciones sin número, antes de avanzar vamos a estandarizar en minúsculas todo el campo "dirección".
"""

bs_maestro_suc['direccion'] =  bs_maestro_suc['direccion'].str.lower()
 bs_maestro_suc['direccion'].head()

bs_maestro_suc['direccion'].value_counts()

"""En las de mayor repetición no parece haber cambios con la conversión a minúsculas"""

bs_maestro_suc[bs_maestro_suc['direccion'].isna()]

"""La dirección de la sucursal 120 que era un número ahora es NaN, por la conversión a texto. Debido al análisis y tratamiento que vamos a llevar adelante, no recuperaremos el número por ser irrelevante para trabajo, cómo tampoco profundizaremos en los datos faltantes de la dirección.

###Campo Localidad
"""

bs_maestro_suc['localidad'].head()

bs_maestro_suc['localidad'].value_counts()

localidades = bs_maestro_suc['localidad'].fillna('').to_list()
localidades = sorted(localidades, key=len, reverse=True)
localidades[:10]

localidades_text = [x for x in localidades if not isinstance(x, str)]
localidades_text

"""Las localidades son textos, salvo el nulo del idSucursal 235."""

localidades_null = bs_maestro_suc['localidad'][bs_maestro_suc['localidad'].isnull()]
localidades_null

"""Detectamos que es posible que haya ciudades con la provincia, en ambos casos están separados por un "-", analizaremos cuantas son las que tienen el separador."""

caracteres_defiltro = "[-]"
localidades_caract = bs_maestro_suc[bs_maestro_suc['localidad'].str.contains(caracteres_defiltro, regex=True, na=False)]
localidades_caract

"""Ambas sucursales ya tienen cargadas las provincias, por lo que avanzaremos eliminando el texto posterior al "-".

Iteramos sobre la columna 'localidad', verificando si el valor es un string, y de tener "-" dividimos y nos quedamos con la primer parte de la cadena.
"""

for idx in range(len(bs_maestro_suc)):
    if isinstance(bs_maestro_suc.loc[idx, 'localidad'], str):
        bs_maestro_suc.loc[idx, 'localidad'] = bs_maestro_suc.loc[idx, 'localidad'].split('-')[0]

"""Test de que fueron actualizadas correctamente."""

bs_maestro_suc[(bs_maestro_suc['idSucursal']==91) | (bs_maestro_suc['idSucursal']==420)]

"""Por último vamos a estandarizar el nombre de las localidades pasandolas a mayúsculas."""

bs_maestro_suc[bs_maestro_suc['localidad'].isna()]

"""Solo la localidad de la idSucursal 235 es NaN"""

bs_maestro_suc['localidad'] = bs_maestro_suc['localidad'].str.upper()

"""###Campo Provincia"""

bs_maestro_suc['provincia'].head()

bs_maestro_suc['provincia'].value_counts().sort_values()

"""###Campo Horarios"""

bs_maestro_suc['horarioLunes'].value_counts()

bs_maestro_suc['horarioMartes'].value_counts()

bs_maestro_suc['horarioMiercoles'].value_counts()

bs_maestro_suc['horarioJueves'].value_counts()

bs_maestro_suc['horarioViernes'].value_counts()

bs_maestro_suc['horarioSabado'].value_counts()

bs_maestro_suc['horarioDomingo'].value_counts()

"""Los horarios estan tipificados, deberémos aplicar las formas normales para optimizar la base."""

bs_maestro_suc['fechaBaja'].value_counts()

bs_maestro_suc['estado'].value_counts()

"""##Formas Normales

De la aplicación de las formas normales surge generar 6 tablas nuevas, reduciendo la redundancia y optimizando para un modelo OLTP

###Subtabla 1
"""

bs_maestro_suc.info()

bs_maestro_suc_1 = bs_maestro_suc[['idSucursal','nombre','fechaAlta','fechaBaja','estado']]
bs_maestro_suc_1.head()

"""###Subtabla 2"""

bs_maestro_suc_2 = bs_maestro_suc[['idSucursal','direccion','localidad','provincia']]
bs_maestro_suc_2.head()

bs_maestro_suc_2 = bs_maestro_suc_2.assign(id_provincia=pd.factorize(bs_maestro_suc_2['provincia'], sort=True)[0])

bs_maestro_suc_2.head()

"""Para que las provincias arranquen en 1, sumamos 1 al id."""

bs_maestro_suc_2['id_provincia'] = bs_maestro_suc_2['id_provincia']+1

"""###Subtabla 3

Creamos la tabla 3, que contiene id provincia y el nombre de la provincia.
"""

bs_maestro_suc_3 = bs_maestro_suc_2[['id_provincia','provincia']].drop_duplicates()
bs_maestro_suc_3 = bs_maestro_suc_3.sort_values(by='id_provincia')
bs_maestro_suc_3

"""Dejamos entonces con id solo la provincia."""

bs_maestro_suc_2 = bs_maestro_suc_2.drop(columns=['provincia'])
bs_maestro_suc_2.head()

"""###Subtabla 5

La 4ta tabla es la relación id sucursal con id del día e id del horario necesitamos despivotear la tabla.
"""

bs_maestro_suc.columns

bs_maestro_suc_4 = bs_maestro_suc[['idSucursal','horarioLunes', 'horarioMartes', 'horarioMiercoles',
       'horarioJueves', 'horarioViernes', 'horarioSabado', 'horarioDomingo']]
bs_maestro_suc_4

bs_maestro_suc_4_unpivoted = bs_maestro_suc_4.melt(id_vars=['idSucursal'],
                                                 value_vars=['horarioLunes', 'horarioMartes', 'horarioMiercoles', 'horarioJueves', 'horarioViernes', 'horarioSabado', 'horarioDomingo'],
                                                 var_name='dia',
                                                 value_name='horario')
dia_mapping = {
    'horarioLunes': 'Lunes',
    'horarioMartes': 'Martes',
    'horarioMiercoles': 'Miercoles',
    'horarioJueves': 'Jueves',
    'horarioViernes': 'Viernes',
    'horarioSabado': 'Sabado',
    'horarioDomingo': 'Domingo'
}

bs_maestro_suc_4_unpivoted['dia'] = bs_maestro_suc_4_unpivoted['dia'].map(dia_mapping)

bs_maestro_suc_4_unpivoted.head()

"""Creamos un id para cada día"""

orden_dias = ['Lunes', 'Martes', 'Miercoles', 'Jueves', 'Viernes', 'Sabado', 'Domingo']
mapeo_dias = {dia: idx + 1 for idx, dia in enumerate(orden_dias)}
bs_maestro_suc_4_unpivoted['id_dia'] = bs_maestro_suc_4_unpivoted['dia'].map(mapeo_dias)
bs_maestro_suc_4_unpivoted['id_dia'] = bs_maestro_suc_4_unpivoted['id_dia'].astype(int)
bs_maestro_suc_4_unpivoted.head()

"""Creamos un id para horario"""

bs_maestro_suc_4_unpivoted = bs_maestro_suc_4_unpivoted.assign(id_horario=pd.factorize(bs_maestro_suc_4_unpivoted['horario'], sort=True)[0])
bs_maestro_suc_4_unpivoted.head()

bs_maestro_suc_5 = bs_maestro_suc_4_unpivoted[['id_dia','dia']].drop_duplicates()
bs_maestro_suc_5

"""###Subtabla 6"""

bs_maestro_suc_6 = bs_maestro_suc_4_unpivoted[['id_horario','horario']].drop_duplicates()
bs_maestro_suc_6 = bs_maestro_suc_6.sort_values(by='id_horario')
bs_maestro_suc_6

"""Para aplicar la 1FN separaremos los valores de horario, en horario de apertura y de cierre."""

bs_maestro_suc_6[['hs_apertura', 'hs_cierre']] = bs_maestro_suc_6['horario'].str.split('-', expand=True)
bs_maestro_suc_6

bs_maestro_suc_6['estado'] = bs_maestro_suc_6['horario'].apply(lambda x: 'Abierto' if 'Cerrado' not in x else 'Cerrado')
bs_maestro_suc_6

bs_maestro_suc_6.loc[bs_maestro_suc_6['estado'] == 'Cerrado', ['hs_apertura', 'hs_cierre']] = None
bs_maestro_suc_6

bs_maestro_suc_6 = bs_maestro_suc_6.drop(columns='horario')
bs_maestro_suc_6 = bs_maestro_suc_6.reset_index(drop=True)
bs_maestro_suc_6

"""###Subtabla 4"""

bs_maestro_suc_4_unpivoted = bs_maestro_suc_4_unpivoted.drop(columns= ['dia','horario'])
bs_maestro_suc_4_unpivoted

"""##Carga a CSV"""

bs_maestro_suc_6.to_csv('bs_maestro_suc_6.csv', index=False)
bs_maestro_suc_4_unpivoted.to_csv('bs_maestro_suc_4_unpivoted.csv', index=False)
bs_maestro_suc_5.to_csv('bs_maestro_suc_5.csv', index=False)
bs_maestro_suc_3.to_csv('bs_maestro_suc_3.csv', index=False)
bs_maestro_suc_2.to_csv('bs_maestro_suc_2.csv', index=False)
bs_maestro_suc_1.to_csv('bs_maestro_suc_1.csv', index=False)

"""##Creación Base SQL - en servidor"""

###SQL para bs_maestro_suc_1.csv:
CREATE TABLE bs_maestro_suc_1 (
  idSucursal INT,
  nombre VARCHAR(255),
  fechaAlta VARCHAR(255),
  fechaBaja FLOAT,
  estado FLOAT
);

###SQL para bs_maestro_suc_2.csv:
CREATE TABLE bs_maestro_suc_2 (
  idSucursal INT,
  direccion VARCHAR(255),
  localidad VARCHAR(255),
  id_provincia INT
);

###SQL para bs_maestro_suc_3.csv:
CREATE TABLE bs_maestro_suc_3 (
  id_provincia INT,
  provincia VARCHAR(255)
);

###SQL para bs_maestro_suc_4_unpivoted.csv:
CREATE TABLE bs_maestro_suc_4_unpivoted (
  idSucursal INT,
  id_dia INT,
  id_horario INT
);

###SQL para bs_maestro_suc_5.csv:
CREATE TABLE bs_maestro_suc_5 (
  id_dia INT,
  dia VARCHAR(255)
);

###SQL para bs_maestro_suc_6.csv:
CREATE TABLE bs_maestro_suc_6 (
  id_horario INT,
  hs_apertura VARCHAR(255),
  hs_cierre VARCHAR(255),
  estado VARCHAR(255)
);

"""##Carga SQL"""

# Conexión a la DDBB
from sqlalchemy import create_engine

USERNAME = "root"
PASSWORD = ""
BBDD = "supermercado"
PORT = "3306"  # Puerto por defecto para MySQL
SERVICE = "localhost"

# Lista de archivos CSV
csv_files = ["bs_maestro_suc_1.csv", "bs_maestro_suc_2.csv", "bs_maestro_suc_3.csv", "bs_maestro_suc_4.csv", "bs_maestro_suc_5.csv","bs_maestro_suc_6.csv"]

if __name__ == "__main__":
    # Creación del motor de conexión
    engine = create_engine(f'mysql+mysqlconnector://{USERNAME}:{PASSWORD}@{SERVICE}:{PORT}/{BBDD}', echo=False)

    # Cargar los CSVs en las tablas
    for csv_file in csv_files:
        table_name = csv_file.split(".")[0]
        df = pd.read_csv(csv_file)
        df.to_sql(table_name, engine, index=False, if_exists='replace')
        print(f"Datos cargados en la tabla {table_name}")

"""#Tabla Maestro Productos:

Nro |Column | Non-Null Count | Dtype |
----- |------- |-------------- |---- |
 0 |idProducto | 14834 non-null  | int64 |
 1 |fechaAlta | 14834 non-null   |datetime64[ns] |
 2 |descripcion |  14834 non-null  | object |
 3 |precioUnitario  | 14834 non-null   |float64 |
 4 |precio  | 11003 non-null   |object |
 5 |categoria | 14834 non-null   |object |
 6 |subCategoria | 14834 non-null   |object |
 7 |fechaBaja | 0 non-null |float64 |
 8 |estado | 0 non-null |float64

##Importar tabla
"""

bs_maestro_prod = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='Maestro PRODUCTOS')
bs_maestro_prod.shape

bs_maestro_prod.head()

bs_maestro_prod.info()

"""##Control tabla

###Campo idProducto
"""

bs_maestro_prod['idProducto'].value_counts()

"""###Campo fechaAlta      """

años = bs_maestro_prod['fechaAlta'].dt.year
años.value_counts()

"""Es razonable el año de alta de cada producto.

###Campo descripcion
"""

bs_maestro_prod['descripcion'].sort_values(key=lambda x: x.str.len(), ascending = False)

"""La descripción no tiene nulos, tiene un detalle del producto, nos puede ayudar a profundizar en alguna carácteristica del mismo.

###Campo precioUnitario
"""

bs_maestro_prod['precioUnitario'].value_counts()

bs_maestro_prod[bs_maestro_prod['precioUnitario']<0]

"""No hay precios errores de precio negativo"""

bs_maestro_prod[bs_maestro_prod['precioUnitario'].isnull()]

"""No hay precios unitarios nulos

###Campo precio
"""

bs_maestro_prod['precio'].head()

"""Tenemos un texto que tiene nulos, unidad, unidad de medida y precio. Debemos serparalos"""

bs_maestro_prod[['cant_medida', 'unidad_medida', 'precio_uni_medida']] = bs_maestro_prod['precio'].str.extract(r'(\d+)\s+([a-zA-Z\s]+):\s*\$(\d+\.\d{2})')
print(bs_maestro_prod[['cant_medida', 'unidad_medida', 'precio_uni_medida']])

bs_maestro_prod['unidad_medida'].value_counts()

"""Detectamos que Kilogramo y Kilo estan considerados separados, tanto en la unidad como en escurrido, dejaremos Kilogramo como correcto."""

bs_maestro_prod['unidad_medida'] = bs_maestro_prod['unidad_medida'].apply(lambda x: "Kilogramo" if pd.notna(x) and x.strip().lower() == "kilo" else x)

bs_maestro_prod['unidad_medida'].value_counts()

"""Falta reemplazar kilo escurrido por kilogramo escurrido, para unificar, ademas de eliminar posibles espacios y por último estandarizar en letra minúscula."""

bs_maestro_prod['unidad_medida'] = bs_maestro_prod['unidad_medida'].apply(lambda x: "kilogramo escurrido" if pd.notna(x) and x.strip().lower() == "kilo escurrido" else x)

bs_maestro_prod['unidad_medida'] = bs_maestro_prod['unidad_medida'].str.strip().str.lower()

bs_maestro_prod['unidad_medida'].value_counts().sort_index()

bs_maestro_prod['cant_medida'].value_counts()

"""Hay medidas que son unitarias otras en 100. revisaremos si hay equivalencias."""

bs_maestro_prod['cant_medida'].info()

un100_medida = bs_maestro_prod[bs_maestro_prod['cant_medida'] == "100"]
value_counts = un100_medida['unidad_medida'].value_counts()

print(value_counts)

"""Los 100 gramos, mililitros y gramos escurridos no hacen equivalencia de otro valor que ya esté calculado.

###Campo categoria
"""

bs_maestro_prod['categoria'].value_counts()

"""En la categoría no hay nulos, ni valores diferentes a las 10 categorías.

###Campo subCategoria
"""

bs_maestro_prod['subCategoria'].value_counts()

"""para eliminar posibles errores procedemos a pasar todo a minúsculas."""

bs_maestro_prod['subCategoria'] = bs_maestro_prod['subCategoria'].str.lower()
bs_maestro_prod['subCategoria'].value_counts()

caracteres_defiltro = "[-]"
localidades_caract = bs_maestro_prod[bs_maestro_prod['subCategoria'].str.contains(caracteres_defiltro, regex=True, na=False)]
localidades_caract['subCategoria'].value_counts()

"""Consideramos que tanto los elementos de panadería de elaboración propia, como los bizcochuelos, no es un error considerarlos como una categoría aparte de productos. Si considerar los vinos en caja en oferta como una categoría diferente a bebidas con alcohol o sin alcohol. Esta identificación como bebida en oferta debería hacerse en otro nivel de clasificación del producto. Proponemos crear una nueva columna con la etiqueta de oferta del vino en caja, pero en la subCategoría clasificarlos como bebidas con alcohol."""

bs_maestro_prod['tiene_oferta'] = bs_maestro_prod['subCategoria'] == "oferta - vinos en caja"

bs_maestro_prod['subCategoria'] = bs_maestro_prod['subCategoria'].str.replace("oferta - vinos en caja", "bebidas con alcohol", case=False)

test_bebidas = bs_maestro_prod[bs_maestro_prod['categoria']=="Bebidas"]
test_bebidas['subCategoria'].value_counts()

"""Las bebidas se sub-categorizaron todas con alcohol o sin alcohol."""

category_count = bs_maestro_prod.groupby('subCategoria')['categoria'].nunique()
multiple_categories = category_count[category_count > 1]
multiple_categories

"""La categoría pastas es la única que se repite en dos categorías distintas, para mejorar la organización de las tablas, vamos a cambiar si el producto es "pasta fresca" si pertenece a alimentos frescos, y a "pasta seca" si pertenece a alimentos secos."""

bs_maestro_prod.loc[
    (bs_maestro_prod['categoria'] == 'Alimentos Frescos') &
    (bs_maestro_prod['subCategoria'] == 'pastas'),
    'subCategoria'
] = 'pastas frescas'

bs_maestro_prod.loc[
    (bs_maestro_prod['categoria'] == 'Alimentos Secos') &
    (bs_maestro_prod['subCategoria'] == 'pastas'),
    'subCategoria'
] = 'pastas secas'

bs_maestro_prod[bs_maestro_prod['subCategoria']=="pastas secas"]

"""###Campo fechaBaja"""



"""###Campo estado"""



"""##Formas Normales

###Subtabla 1
"""

bs_maestro_prod.head()

bs_maestro_prod.columns

bs_maestro_prod_1 = bs_maestro_prod[['idProducto', 'fechaAlta', 'descripcion', 'fechaBaja', 'estado', 'tiene_oferta']]
bs_maestro_prod_1

"""###Subtabla 3"""

bs_maestro_prod_2 = bs_maestro_prod[['idProducto', 'precioUnitario', 'cant_medida', 'unidad_medida', 'precio_uni_medida']]
bs_maestro_prod_2

bs_maestro_prod_2 = bs_maestro_prod_2.assign(id_uni_medida=pd.factorize(bs_maestro_prod_2['unidad_medida'], sort=True)[0])
bs_maestro_prod_2.head()

bs_maestro_prod_2['id_uni_medida']=bs_maestro_prod_2['id_uni_medida']+1

bs_maestro_prod_3 = bs_maestro_prod_2[['id_uni_medida', 'unidad_medida']].drop_duplicates()
bs_maestro_prod_3 = bs_maestro_prod_3.sort_values(by='id_uni_medida')
bs_maestro_prod_3 = bs_maestro_prod_3.reset_index(drop=True)
bs_maestro_prod_3

bs_maestro_prod_2 = bs_maestro_prod_2.drop(columns='unidad_medida')
bs_maestro_prod_2.head()

"""###Subtabla 2"""

bs_maestro_prod_2 = bs_maestro_prod_2.reindex(['idProducto', 'precioUnitario', 'cant_medida', 'id_uni_medida', 'precio_uni_medida'], axis = 1)
bs_maestro_prod_2.head()

"""###Subtabla 5"""

bs_maestro_prod_4 = bs_maestro_prod[['idProducto','subCategoria', 'categoria']]
bs_maestro_prod_4.head()

bs_maestro_prod_4 = bs_maestro_prod_4.assign(idSubcategoria=pd.factorize(bs_maestro_prod_4['subCategoria'], sort=True)[0])
bs_maestro_prod_4['idSubcategoria'] = bs_maestro_prod_4['idSubcategoria']+1
bs_maestro_prod_4.head()

bs_maestro_prod_5 = bs_maestro_prod_4[['idProducto','subCategoria', 'categoria', 'idSubcategoria']].drop_duplicates(subset='idSubcategoria', keep="last")
bs_maestro_prod_5.head()

bs_maestro_prod_5 = bs_maestro_prod_5.drop(columns='idProducto')
bs_maestro_prod_5 = bs_maestro_prod_5.reset_index(drop=True)
bs_maestro_prod_5 = bs_maestro_prod_5.reindex(['idSubcategoria','subCategoria','categoria'], axis = 1)
bs_maestro_prod_5.head()

"""###Subtabla 4"""

bs_maestro_prod_4 = bs_maestro_prod_4.drop(columns=['subCategoria','categoria'])
bs_maestro_prod_4

"""##Carga CSV"""

bs_maestro_prod_1.to_csv('bs_maestro_prod_1.csv', index=False)
bs_maestro_prod_2.to_csv('bs_maestro_prod_2.csv', index=False)
bs_maestro_prod_3.to_csv('bs_maestro_prod_3.csv', index=False)
bs_maestro_prod_4.to_csv('bs_maestro_prod_4.csv', index=False)
bs_maestro_prod_5.to_csv('bs_maestro_prod_5.csv', index=False)

"""##Creación Base SQL - en servidor"""

###SQL para bs_maestro_prod_1.csv:
CREATE TABLE bs_maestro_prod_1 (
  idProducto INT,
  fechaAlta VARCHAR(255),
  descripcion VARCHAR(255),
  fechaBaja FLOAT,
  estado FLOAT,
  tiene_oferta VARCHAR(255)
);

###SQL para bs_maestro_prod_2.csv:
CREATE TABLE bs_maestro_prod_2 (
  idProducto INT,
  precioUnitario FLOAT,
  cant_medida FLOAT,
  id_uni_medida INT,
  precio_uni_medida FLOAT
);

###SQL para bs_maestro_prod_3.csv:
CREATE TABLE bs_maestro_prod_3 (
  id_uni_medida INT,
  unidad_medida VARCHAR(255)
);

###SQL para bs_maestro_prod_4.csv:
CREATE TABLE bs_maestro_prod_4 (
  idProducto INT,
  idSubcategoria INT
);

"""##Carga SQL"""

# Conexión a la DDBB
from sqlalchemy import create_engine

USERNAME = "root"
PASSWORD = ""
BBDD = "supermercado"
PORT = "3306"  # Puerto por defecto para MySQL
SERVICE = "localhost"

# Lista de archivos CSV
csv_files = ["bs_maestro_prod_1.csv", "bs_maestro_prod_2.csv", "bs_maestro_prod_3.csv", "bs_maestro_prod_4.csv"]

if __name__ == "__main__":
    # Creación del motor de conexión
    engine = create_engine(f'mysql+mysqlconnector://{USERNAME}:{PASSWORD}@{SERVICE}:{PORT}/{BBDD}', echo=False)

    # Cargar los CSVs en las tablas
    for csv_file in csv_files:
        table_name = csv_file.split(".")[0]
        df = pd.read_csv(csv_file)
        df.to_sql(table_name, engine, index=False, if_exists='replace')
        print(f"Datos cargados en la tabla {table_name}")

"""#Tabla Inventario:

##Importar tabla
"""

bs_inventario = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='INVENTARIO')
bs_inventario.shape

bs_inventario.info()

"""##Control tabla

###Campo IdSucursal e IdProducto

La tabla muestra el inventario de cada sucursal de cada producto, por lo que la relación idSucursal idProducto debería ser unica.
"""

bs_inventario['id_inventario']= bs_inventario['idSucursal'].astype(str) +"_"+ bs_inventario['idProducto'].astype(str)
bs_inventario.head()

bs_inventario['id_inventario'].value_counts()

"""Hay sucursales que tienen mas de una vez un producto"""

bs_inventario[bs_inventario['id_inventario']=='416_12161']

"""Tomaremos el supuesto de que ha ocurrido un error en la empresa que ha provocado la duplicación en mas de una ocasión de ciertos registros de inventario. Para resolver esto, mantendremos únicamente el último registro de cada producto por sucursal, descartando los registros anteriores. Dado que no contamos con fechas que indiquen el momento del registro, utilizaremos el índice como referencia para determinar el orden."""

bs_inventario_ord = bs_inventario.sort_index(ascending=False)
bs_inventario_mod = bs_inventario_ord.drop_duplicates(subset=['idSucursal', 'idProducto'], keep='first')

bs_inventario_mod['id_inventario'].value_counts()

"""Cada combinación de idSucursal y idProducto está una sola vez."""

bs_inventario_mod.info()

bs_inventario_mod.head()

"""###Campo cantidadEnStock"""

bs_inventario_mod['cantidadEnStock'].describe()

"""La cantidad mínima es 1, no hay cantidades negativas, y la máxima es 4000, no hay indicios de error.

###Campo cantidadParareposicion
"""

bs_inventario_mod['cantidadParaReposicion'].describe()

"""Las cantidades de reposición son mayores a 100 el mínimo, el máximo 4000. No hay indicios de error."""

conteo_cantidades = bs_inventario_mod.groupby('idProducto')['cantidadParaReposicion'].nunique()
productos_con_diferentes_cantidades = conteo_cantidades[conteo_cantidades > 1]
print(productos_con_diferentes_cantidades)

bs_inventario_mod[bs_inventario_mod['idProducto']==1]

"""Para un mismo producto, en diferentes sucursales la cantidad para la reposición es diferente.

###Campo reposicionPedida
"""

bs_inventario_mod['reposicionPedida'].value_counts()

"""El valor positivo 1 es el true, el negativo es 0, y el resto es null.

###Campo cantidadPedida
"""

bs_inventario_mod['cantidadPedida'].value_counts()

bs_inventario_mod['cantidadPedida'].describe()

"""La cantidad de reposiciones pedidas coincide con el importe de reposicionPedida positivas. No hay indicios de error.

##Formas Normales

Como la cantidad de Reposición no depende solo del producto, sino de cada sucursal también, es decir la columna depende de la id_inventario, por lo que se estaría aplicando las 3FN.
El resto de las columnas también dependen de la columna id_inventario, se siguen aplicando las 3FN

###Subtabla 1
"""

bs_inventario_mod.columns

bs_inventario_mod_1 = bs_inventario_mod[['idSucursal', 'idProducto', 'cantidadEnStock', 'cantidadParaReposicion', 'id_inventario']]

bs_inventario_mod_1

bs_inventario_mod_1 = bs_inventario_mod_1.reindex(['id_inventario', 'idProducto', 'idSucursal', 'cantidadEnStock', 'cantidadParaReposicion'], axis=1)
bs_inventario_mod_1 = bs_inventario_mod_1.reset_index(drop=True)
bs_inventario_mod_1

"""###Subtabla 3"""

bs_inventario_mod_2 =  bs_inventario_mod[['id_inventario', 'cantidadPedida', 'reposicionPedida']]
bs_inventario_mod_2

bs_inventario_mod_2 = bs_inventario_mod_2.assign(id_repo=pd.factorize(bs_inventario_mod_2['reposicionPedida'], sort=True)[0])
bs_inventario_mod_2['id_repo'] = bs_inventario_mod_2['id_repo']+1
bs_inventario_mod_2.head()

bs_inventario_mod_3 = bs_inventario_mod_2[['id_repo', 'reposicionPedida']].drop_duplicates(subset = 'id_repo', keep='last')
bs_inventario_mod_3 = bs_inventario_mod_3.reset_index(drop=True)
bs_inventario_mod_3

"""###Subtabla 2"""

bs_inventario_mod_2 = bs_inventario_mod_2.drop(columns='reposicionPedida')
bs_inventario_mod_2 = bs_inventario_mod_2.reindex(['id_inventario', 'id_repo', 'cantidadPedida'], axis=1)
bs_inventario_mod_2 = bs_inventario_mod_2.reset_index(drop=True)
bs_inventario_mod_2

"""##Carga a CSV"""

bs_inventario_mod_1.to_csv('bs_inventario_mod_1.csv', index=False)
bs_inventario_mod_2.to_csv('bs_inventario_mod_2.csv', index=False)
bs_inventario_mod_3.to_csv('bs_inventario_mod_3.csv', index=False)

"""#Tabla Maestro Clientes:"""

bs_maestro_clientes.info()

"""##Importar tabla"""

bs_maestro_clientes = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='Maestro CLIENTES')
bs_maestro_clientes.shape

bs_maestro_clientes.head()

bs_maestro_clientes.info()

"""##Control tabla

###Campo idCliente
"""

bs_maestro_clientes['idCliente'].value_counts()

"""No hay repetidos, puede ser el PK"""

bs_maestro_clientes['idCliente'].describe()

"""###Campo fechaAlta"""

bs_maestro_clientes['fechaAlta'].value_counts()

años = bs_maestro_clientes['fechaAlta'].dt.year
años.value_counts()

"""No hay evidencia de errores en las fechas, los años son del rango razonable de alta de clientes.

###Campo fechaNacimiento
"""

bs_maestro_clientes['fechaNacimiento'].value_counts()

años = bs_maestro_clientes['fechaNacimiento'].dt.year
años.value_counts()

años.describe()

"""El cliente mayor es de 1930, y el mas chico de 2005. Son fechas razonables para clientes que se dieron de alta entre el 2000 y 2020. La consistencia que habría que analizar es si hay clientes que se dieron de alta previo a la fecha de nacimiento. Vamos a calcular la diferencia en años entre fecha de alta y de nacimiento."""

bs_maestro_clientes_b = bs_maestro_clientes

bs_maestro_clientes_b['año_alta'] = bs_maestro_clientes_b['fechaAlta'].dt.year
bs_maestro_clientes_b['año_nac'] = bs_maestro_clientes_b['fechaNacimiento'].dt.year
bs_maestro_clientes_b['dif_años'] = bs_maestro_clientes_b['año_alta'] - bs_maestro_clientes_b['año_nac']

bs_maestro_clientes_b['dif_años'].describe()

bs_maestro_clientes_b[bs_maestro_clientes_b['dif_años']==0]

"""Trabajaremos bajo el supuesto que la fechaNacimiento es la fecha de alta de la sociedad del cliente, y no de nacimiento del mismo.

###Campo genero
"""

bs_maestro_clientes['genero'].value_counts()

bs_maestro_clientes[bs_maestro_clientes['genero']=="indefinido"]

"""###Campo nombre"""

bs_maestro_clientes['nombre'].value_counts()

ord = bs_maestro_clientes.loc[bs_maestro_clientes['nombre'].str.len().sort_values(ascending=False).index]

ord

"""Los nombres de máximo largo no tienen indicios de error.

###Campo apellido
"""

ord_2 = bs_maestro_clientes.loc[bs_maestro_clientes['apellido'].str.len().sort_values(ascending=False).index]
ord_2

"""Los apellidos tampoco tienen indicios de error.

###Campo email
"""

bs_maestro_clientes['email'].value_counts()

"""Los mails no aparentan tener error, si puede llamar la antención que haya diferentes clientes con el mismo mail."""

bs_maestro_clientes[bs_maestro_clientes['email']=="rafael.rodriguez@gmail.com"]

"""Se llaman de la misma forma y viven en distintos lugares, distinto año de nacimiento, no será utilizado el email para el análisis que se realice."""

ord_3 = bs_maestro_clientes.loc[bs_maestro_clientes['email'].str.len().sort_values(ascending=False).index]
ord_3

"""Los mails mas largos no incluyen información de otra columna ni erronea.

###Campo dirección
"""

bs_maestro_clientes['direccion'].value_counts()

"""Vamos a estandarizar aplicandole minúsculas a todas las direcciones."""

no_text = bs_maestro_clientes[~bs_maestro_clientes['direccion'].apply(lambda x: isinstance(x, str))]
no_text

"""Hay varias direcciones que son fecha y hora, vamos a estandarizarlas y estas quedaran como NaN"""

bs_maestro_clientes['direccion'] =  bs_maestro_clientes['direccion'].str.lower()

bs_maestro_clientes[bs_maestro_clientes['direccion'].isna()]

bs_maestro_clientes.info()

"""###Campo ciudad"""

bs_maestro_clientes['ciudad'].value_counts()

caracteres_defiltro = "[-]"
ciudad_caract = bs_maestro_clientes[bs_maestro_clientes['ciudad'].str.contains(caracteres_defiltro, regex=True, na=False)]
ciudad_caract

"""Para dejar la ciudad limpia, vamos a agregar la información adicional del campo a referencia."""

split_columns = bs_maestro_clientes['ciudad'].str.split(r'\s*-\s*', n=1, expand=True)
split_columns[1] = split_columns[1].fillna('')
bs_maestro_clientes['ciudad'] = split_columns[0]
bs_maestro_clientes['referencia'] = bs_maestro_clientes['referencia'].fillna('').astype(str)
split_columns[1] = split_columns[1].astype(str)
bs_maestro_clientes['referencia'] = bs_maestro_clientes['referencia'] + ' ' + split_columns[1]
bs_maestro_clientes['referencia'] = bs_maestro_clientes['referencia'].str.strip()
print(bs_maestro_clientes[['ciudad', 'referencia']])

"""###Campo provincia"""

bs_maestro_clientes['provincia'].value_counts()

bs_maestro_clientes['provincia'].value_counts().sort_index()

"""Detectamos errores en Entre Rios, Córdoba, Rio Negro y Neuquén. Reemplazaremos por los valores correctos."""

reemplazos = {
    'Ro Negro': 'Río Negro',
    'Entre Ros': 'Entre Ríos',
    'Crdoba': 'Córdoba',
    'Neuqun': 'Neuquén'
}
bs_maestro_clientes['provincia'] = bs_maestro_clientes['provincia'].replace(reemplazos)

bs_maestro_clientes['provincia'].value_counts().sort_index()

"""##Formas Normales"""

bs_maestro_clientes.columns

"""###Subtabla 1"""

bs_maestro_clientes_1 = bs_maestro_clientes[['idCliente', 'fechaAlta', 'fechaNacimiento', 'nombre',
       'apellido', 'email', 'fechaBaja', 'estado']]

"""###Subtabla 3"""

bs_maestro_clientes_2 = bs_maestro_clientes[['idCliente', 'genero']]
bs_maestro_clientes_2 = bs_maestro_clientes_2.assign(id_genero=pd.factorize(bs_maestro_clientes_2['genero'], sort=True)[0])
bs_maestro_clientes_2['id_genero'] = bs_maestro_clientes_2['id_genero']+1
bs_maestro_clientes_2

bs_maestro_clientes_3 = bs_maestro_clientes_2[['id_genero','genero']].drop_duplicates(subset='id_genero', keep="last")
bs_maestro_clientes_3 = bs_maestro_clientes_3.sort_values(by=['id_genero'])
bs_maestro_clientes_3 = bs_maestro_clientes_3.reset_index(drop=True)
bs_maestro_clientes_3.head()

"""###Subtabla 2"""

bs_maestro_clientes_2 = bs_maestro_clientes_2.drop(columns='genero')
bs_maestro_clientes_2.head()

bs_maestro_clientes_4 = bs_maestro_clientes[['idCliente', 'direccion', 'ciudad', 'referencia', 'provincia']]
bs_maestro_clientes_4 = bs_maestro_clientes_4.assign(id_prov=pd.factorize(bs_maestro_clientes_4['provincia'], sort=True)[0])
bs_maestro_clientes_4['id_prov'] = bs_maestro_clientes_4['id_prov']+1
bs_maestro_clientes_4.head()

bs_maestro_clientes_5 = bs_maestro_clientes_4[['id_prov', 'provincia']].drop_duplicates(subset='id_prov', keep="last")
bs_maestro_clientes_5 = bs_maestro_clientes_5.sort_values(by=['id_prov'])
bs_maestro_clientes_5 = bs_maestro_clientes_5.reset_index(drop=True)
bs_maestro_clientes_5

bs_maestro_clientes_4 = bs_maestro_clientes_4.drop(columns='provincia')
bs_maestro_clientes_4.head()

"""##Carga CSV"""

bs_maestro_clientes_1.to_csv('bs_maestro_clientes_1.csv', index=False)
bs_maestro_clientes_2.to_csv('bs_maestro_clientes_2.csv', index=False)
bs_maestro_clientes_3.to_csv('bs_maestro_clientes_3.csv', index=False)
bs_maestro_clientes_4.to_csv('bs_maestro_clientes_4.csv', index=False)
bs_maestro_clientes_5.to_csv('bs_maestro_clientes_5.csv', index=False)

"""##Creación Base SQL - en servidor"""

###SQL para bs_maestro_clientes_1.csv:
CREATE TABLE bs_maestro_clientes_1 (
  idCliente INT,
  fechaAlta VARCHAR(255),
  fechaNacimiento VARCHAR(255),
  nombre VARCHAR(255),
  apellido VARCHAR(255),
  email VARCHAR(255),
  fechaBaja FLOAT,
  estado FLOAT
);

###SQL para bs_maestro_clientes_2.csv:
CREATE TABLE bs_maestro_clientes_2 (
  idCliente INT,
  id_genero INT
);

###SQL para bs_maestro_clientes_3.csv:
CREATE TABLE bs_maestro_clientes_3 (
  id_genero INT,
  genero VARCHAR(255)
);

###SQL para bs_maestro_clientes_4.csv:
CREATE TABLE bs_maestro_clientes_4 (
  idCliente INT,
  direccion VARCHAR(255),
  ciudad VARCHAR(255),
  referencia VARCHAR(255),
  id_prov INT
);

###SQL para bs_maestro_clientes_5.csv:
CREATE TABLE bs_maestro_clientes_5 (
  id_prov INT,
  provincia VARCHAR(255)
);

"""##Carga SQL"""

# Conexión a la DDBB
from sqlalchemy import create_engine

USERNAME = "root"
PASSWORD = ""
BBDD = "supermercado"
PORT = "3306"  # Puerto por defecto para MySQL
SERVICE = "localhost"

# Lista de archivos CSV
csv_files = ["bs_maestro_clientes_1.csv", "bs_maestro_clientes_2.csv", "bs_maestro_clientes_3.csv", "bs_maestro_clientes_4.csv", "bs_maestro_clientes_5.csv"]

if __name__ == "__main__":
    # Creación del motor de conexión
    engine = create_engine(f'mysql+mysqlconnector://{USERNAME}:{PASSWORD}@{SERVICE}:{PORT}/{BBDD}', echo=False)

    # Cargar los CSVs en las tablas
    for csv_file in csv_files:
        table_name = csv_file.split(".")[0]
        df = pd.read_csv(csv_file)
        df.to_sql(table_name, engine, index=False, if_exists='replace')
        print(f"Datos cargados en la tabla {table_name}")

"""#Tabla Ordenes:"""

bs_ordenes.info()

"""##Importar tabla"""

bs_ordenes = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='ORDENES')
bs_ordenes.shape

bs_ordenes.head()

"""##Control tabla

###Control idOrden
"""

bs_ordenes['idOrden'].value_counts()

"""No hay idOrden repetidas, puede ser el PK de la tabla."""

bs_ordenes['idOrden'].describe()

"""Hay 100.072 registros y el número máximo de idOrden de registros es 100.099. Hay una diferencia de 27 movimientos no registrados en la tabla, o registrados pero que fueron borrados. Consideraremos para este trabajo como no significativo los 27 casos faltantes en un universo de 100.072 operaciones."""

bs_ordenes[bs_ordenes['idOrden']==23668]

"""###Control montoTotal"""

bs_ordenes['montoTotal'].describe()

"""###Campo fechaCompra"""

años = bs_ordenes['fechaCompra'].dt.year
años.value_counts()

años.describe()

"""Los años son razonables de operación, no hay indicio de error en fechas de compras.

###Campo idCliente
"""

bs_ordenes['idCliente'].value_counts()

bs_ordenes['idCliente'].describe()

"""Coincide el idCliente mayor, 25189 con el maestro clientes.

###Campo Sucursal
"""

bs_ordenes['idSucursal'].describe()

bs_ordenes['idSucursal'].nunique()

"""El id máximo de sucursal también coincide con el máximo de idSucursal del Maestro sucursales.

###Campo metodoDePago
"""

bs_ordenes['metodoDePago'].value_counts()

"""Los medios de pagos estan tipificados, no hay indicios de error.

###Campo estado
"""

bs_ordenes['estado'].value_counts()

"""Los estados están tipificados, no hay indicios de error.

##Formas Normales
"""

bs_ordenes.columns

bs_ordenes_1 = bs_ordenes[['idOrden', 'montoTotal', 'fechaCompra', 'idCliente', 'idSucursal']]
bs_ordenes_1.head()

bs_ordenes_2 = bs_ordenes[['idOrden', 'metodoDePago']]
bs_ordenes_2 = bs_ordenes_2.assign(id_metpago=pd.factorize(bs_ordenes_2['metodoDePago'], sort=True)[0])
bs_ordenes_2['id_metpago'] = bs_ordenes_2['id_metpago']+1
bs_ordenes_2.head()

bs_ordenes_3 = bs_ordenes_2[['id_metpago','metodoDePago']].drop_duplicates(subset='id_metpago', keep="last")
bs_ordenes_3 = bs_ordenes_3.sort_values(by=['id_metpago'])
bs_ordenes_3 = bs_ordenes_3.reset_index(drop=True)
bs_ordenes_3

bs_ordenes_2 = bs_ordenes_2.drop('metodoDePago', axis=1)
bs_ordenes_2

bs_ordenes_4 = bs_ordenes[['idOrden','estado']]
bs_ordenes_4 = bs_ordenes_4.assign(id_estado=pd.factorize(bs_ordenes_4['estado'], sort=True)[0])
bs_ordenes_4['id_estado'] = bs_ordenes_4['id_estado']+1
bs_ordenes_4

bs_ordenes_5 = bs_ordenes_4[['id_estado','estado']].drop_duplicates(subset='id_estado', keep="last")
bs_ordenes_5 = bs_ordenes_5.sort_values(by=['id_estado'])
bs_ordenes_5 = bs_ordenes_5.reset_index(drop=True)
bs_ordenes_5

bs_ordenes_4 = bs_ordenes_4.drop('estado', axis=1)
bs_ordenes_4.head()

"""##Carga CSV"""

bs_ordenes_1.to_csv('bs_ordenes_1.csv', index=False)
bs_ordenes_2.to_csv('bs_ordenes_2.csv', index=False)
bs_ordenes_3.to_csv('bs_ordenes_3.csv', index=False)
bs_ordenes_4.to_csv('bs_ordenes_4.csv', index=False)
bs_ordenes_5.to_csv('bs_ordenes_5.csv', index=False)

"""##Creación Base SQL - en servidor"""

###SQL para bs_ordenes_1.csv:
CREATE TABLE bs_ordenes_1 (
  idOrden INT,
  montoTotal FLOAT,
  fechaCompra VARCHAR(255),
  idCliente INT,
  idSucursal INT
);

###SQL para bs_ordenes_2.csv:
CREATE TABLE bs_ordenes_2 (
  idOrden INT,
  id_metpago INT
);

###SQL para bs_ordenes_3.csv:
CREATE TABLE bs_ordenes_3 (
  id_metpago INT,
  metodoDePago VARCHAR(255)
);

###SQL para bs_ordenes_4.csv:
CREATE TABLE bs_ordenes_4 (
  idOrden INT,
  id_estado INT
);

###SQL para bs_ordenes_5.csv:
CREATE TABLE bs_ordenes_5 (
  id_estado INT,
  estado VARCHAR(255)
);

"""##Carga SQL"""

# Conexión a la DDBB
from sqlalchemy import create_engine

USERNAME = "root"
PASSWORD = ""
BBDD = "supermercado"
PORT = "3306"  # Puerto por defecto para MySQL
SERVICE = "localhost"

# Lista de archivos CSV
csv_files = ["bs_ordenes_1.csv", "bs_ordenes_2.csv", "bs_ordenes_3.csv", "bs_ordenes_4.csv", "bs_ordenes_5.csv"]

if __name__ == "__main__":
    # Creación del motor de conexión
    engine = create_engine(f'mysql+mysqlconnector://{USERNAME}:{PASSWORD}@{SERVICE}:{PORT}/{BBDD}', echo=False)

    # Cargar los CSVs en las tablas
    for csv_file in csv_files:
        table_name = csv_file.split(".")[0]
        df = pd.read_csv(csv_file)
        df.to_sql(table_name, engine, index=False, if_exists='replace')
        print(f"Datos cargados en la tabla {table_name}")

"""#Tabla Ordenes detalle:"""

bs_ordenes_det.info()

"""##Importar tabla"""

bs_ordenes_det = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='ORDENES_DETALLE')
bs_ordenes_det.shape

bs_ordenes_det.head()

"""##Control tabla

###Campo idOrden
"""

bs_ordenes_det['idOrden'].value_counts()

bs_ordenes_det['idOrden'].describe()

"""El idOrden máximo es 100.099, igual que la tabla ordenes."""

bs_ordenes_det['idOrden'].nunique()

"""Y un total de idOrden distintos de 100.072 igual también que la tabla ordenes.

###Campo idProducto
"""

bs_ordenes_det['idProducto'].value_counts()

bs_ordenes_det['idProducto'].describe()

"""El idProducto máximo coincide con el id máximo de la tabla maestro de productos.

###Campo cantidad
"""

bs_ordenes_det['cantidad'].describe()

bs_ordenes_det['cantidad'].value_counts()

"""Las cantidades son todas mayores a 0, y el máximo es 12 productos, lo que es razonable, no hay indicios de errores.

###Campo preciounitario
"""

bs_ordenes_det['precioUnitario'].value_counts()

bs_ordenes_det['precioUnitario'].describe()

"""Los precios unitarios no tienen indicios de error en su columna, son razonables, son mayores a 0 y no poseen valores nulos.

###Campo precio
"""

bs_ordenes_det['precio'].value_counts()

bs_ordenes_det['precio'].describe()

bs_ordenes_det['precio'].nunique()

"""###Campo id_orden_prod

Crearemos un id único para la tabla en detalle, concatenando el idOrden y idProducto
"""

bs_ordenes_det['id_ord_prod']= bs_ordenes_det['idOrden'].astype(str) +"_"+ bs_ordenes_det['idProducto'].astype(str)

bs_ordenes_det

bs_ordenes_det['id_ord_prod'].value_counts()

bs_ordenes_det[bs_ordenes_det['id_ord_prod']=="23668_8207"]

bs_ordenes_det['calc'] = np.where(bs_ordenes_det['cantidad'] * bs_ordenes_det['precioUnitario'] == bs_ordenes_det['precio'], 'A', 'M')
bs_ordenes_det

"""Los valores de la sumatoria de los productos de una orden, no totalizan el importe de montototal de la tabla ordenes. Para avanzar con el análisis sumaremos las cantidades y volveremos a calcular el precio total."""

bs_ordenes_det_mod = bs_ordenes_det.groupby('id_ord_prod').agg({
    'idOrden': 'last',              # Primer valor de 'idOrden'
    'idProducto': 'last',           # Primer valor de 'idProducto'
    'cantidad': 'sum',               # Sumar la columna 'cantidad'
    'precioUnitario': 'last',       # Primer valor de 'precioUnitario'
    'precio': 'sum',               # Primer valor de 'precio'
    'calc': 'last'                  # Primer valor de 'calc'
}).reset_index()

bs_ordenes_det[bs_ordenes_det['id_ord_prod']=="23668_8207"]

bs_ordenes_det_mod[bs_ordenes_det_mod['id_ord_prod']=="23668_8207"]

"""Tomamos como ejemplo la id_ord_prod 23668_8207 son 14 productos a 19.99 valor total 279.86.
Procedemos a revisar si todos las cantidades por precioUnitario es igual al precio.

"""

bs_ordenes_det_mod['calc'] = np.where((bs_ordenes_det_mod['cantidad'] * bs_ordenes_det_mod['precioUnitario']).round(2) == bs_ordenes_det_mod['precio'].round(2), 'A', 'M')
bs_ordenes_det_mod[bs_ordenes_det_mod['calc']=="M"]

"""No hay diferencia entre el calculo de cantidad x precioUnitario y el precio. Redondeamos en 2 decimales para eliminar error de decimales."""

bs_ordenes_det_mod = bs_ordenes_det_mod.drop(['calc'], axis=1)

bs_ordenes_det_mod

bs_ordenes_det_mod[bs_ordenes_det_mod['id_ord_prod']=="91895_1042"]

"""##Formas Normales"""

bs_ordenes_det_mod.columns

bs_ordenes_det_mod_1 = bs_ordenes_det_mod[['id_ord_prod', 'idOrden', 'idProducto', 'cantidad', 'precioUnitario', 'precio']]

"""##Carga CSV"""

bs_ordenes_det_mod_1.to_csv('bs_ordenes_det_mod_1.csv', index=False)

"""##Creación Base SQL - en servidor"""

###SQL para bs_ordenes_det_mod_1.csv:
CREATE TABLE bs_ordenes_det_mod_1 (
  id_ord_prod VARCHAR(255),
  idOrden INT,
  idProducto INT,
  cantidad INT,
  precioUnitario FLOAT,
  precio FLOAT
);

"""##Carga a SQL"""

# Conexión a la DDBB
from sqlalchemy import create_engine

USERNAME = "root"
PASSWORD = ""
BBDD = "supermercado"
PORT = "3306"  # Puerto por defecto para MySQL
SERVICE = "localhost"

# Lista de archivos CSV
csv_files = ["bs_ordenes_det_mod_1.csv"]

if __name__ == "__main__":
    # Creación del motor de conexión
    engine = create_engine(f'mysql+mysqlconnector://{USERNAME}:{PASSWORD}@{SERVICE}:{PORT}/{BBDD}', echo=False)

    # Cargar los CSVs en las tablas
    for csv_file in csv_files:
        table_name = csv_file.split(".")[0]
        df = pd.read_csv(csv_file)
        df.to_sql(table_name, engine, index=False, if_exists='replace')
        print(f"Datos cargados en la tabla {table_name}")

"""#Tabla Devoluciones:"""

bs_devoluciones.info()

"""##Importar tabla"""

bs_devoluciones = pd.read_excel('/content/drive/MyDrive/UBA_diplo2024/Base_Diplo_Datos_Supermercado.xlsx', sheet_name='DEVOLUCIONES')
bs_devoluciones.shape

bs_devoluciones.head()

"""##Control tabla

###Campo idOrden
"""

bs_devoluciones['idOrden'].value_counts()

bs_devoluciones['idOrden'].describe()

"""En las devoluciones hay mas de un idproducto, los números de idOrden coinciden con los de las otras tablas.

###Campo idProducto
"""

bs_devoluciones['idProducto'].value_counts()

bs_devoluciones['idProducto'].describe()

"""El número máximo de idProducto esta dentro del rango de los id de productos de la tabla maestro de productos.

### Campo cantidadDevuelta
"""

bs_devoluciones['cantidadDevuelta'].value_counts()

"""La cantidad minima devuelta es 1, no hay ninguna con 0, y máxima 12, no hay indicios de error."""

bs_devoluciones['cantidadDevuelta'].describe()

"""El promedio de cantidad devuelta es 3,75. Es razonable siendo que es menor a la cantidad promedio de items comprados."""

bs_devoluciones['fechaDevolucion'].value_counts()

años = bs_devoluciones['fechaDevolucion'].dt.year
años.value_counts()

"""Los años de las fechas de devolución son razonables. No hay indicios de error.

###Campo motivoDevolucion
"""

bs_devoluciones['motivoDevolucion'].value_counts()

"""Los motivos de devolución estan tipificados, no hay indicios de error.

### Campo resolucion
"""

bs_devoluciones['resolucion'].value_counts()

"""Las resoluciones estan tipificadas, no hay indicios de error.

###Campo id_ord_prod
"""

bs_devoluciones['id_ord_prod']= bs_devoluciones['idOrden'].astype(str) +"_"+ bs_devoluciones['idProducto'].astype(str)
bs_devoluciones

bs_devoluciones['id_ord_prod'].value_counts()

bs_devoluciones[bs_devoluciones['id_ord_prod']=="91895_1042"]

"""La orden 91895 tiene el producto 1042 que ha sido registrada la devolución dos veces, nos quedamos con la segunda, debido a que es la posterior, y trabajamos bajo el supuesto que hubo un inconveniente con el reembolso."""

bs_devoluciones = bs_devoluciones.drop(index=19104)

bs_devoluciones['id_ord_prod'].value_counts()

"""De esta forma el id_ord_prod puede ser PK de la tabla.

##Formas Normales

###Subtabla 1
"""

bs_devoluciones.columns

bs_devoluciones_1 = bs_devoluciones[['idOrden', 'idProducto', 'cantidadDevuelta', 'fechaDevolucion', 'id_ord_prod']]
bs_devoluciones_1 = bs_devoluciones_1.reindex(['id_ord_prod', 'idOrden', 'idProducto', 'cantidadDevuelta', 'fechaDevolucion'], axis =1)
bs_devoluciones_1

"""###Subtabla 3"""

bs_devoluciones_2 = bs_devoluciones[['id_ord_prod', 'motivoDevolucion']]
bs_devoluciones_2 = bs_devoluciones_2.assign(id_motdev=pd.factorize(bs_devoluciones_2['motivoDevolucion'], sort=True)[0])
bs_devoluciones_2['id_motdev'] = bs_devoluciones_2['id_motdev']+1
bs_devoluciones_2.head()

bs_devoluciones_3 = bs_devoluciones_2[['id_motdev', 'motivoDevolucion']].drop_duplicates(subset='id_motdev', keep="last")
bs_devoluciones_3 = bs_devoluciones_3.reset_index(drop=True)
bs_devoluciones_3

"""###Subtabla 2"""

bs_devoluciones_2 = bs_devoluciones_2.drop('motivoDevolucion', axis=1)
bs_devoluciones_2.head()

"""###Subtabla 5"""

bs_devoluciones_4 = bs_devoluciones[['id_ord_prod', 'resolucion']]
bs_devoluciones_4 = bs_devoluciones_4.assign(id_resol=pd.factorize(bs_devoluciones_4['resolucion'], sort=True)[0])
bs_devoluciones_4['id_resol'] = bs_devoluciones_4['id_resol']+1
bs_devoluciones_4.head()

bs_devoluciones_5 = bs_devoluciones_4[['id_resol', 'resolucion']].drop_duplicates(subset='id_resol', keep="last")
bs_devoluciones_5 = bs_devoluciones_5.sort_values(by='id_resol')
bs_devoluciones_5 = bs_devoluciones_5.reset_index(drop=True)
bs_devoluciones_5

"""###Subtabla 4"""

bs_devoluciones_4 = bs_devoluciones_4.drop('resolucion', axis=1)
bs_devoluciones_4

"""##Carga CSV"""

bs_devoluciones_1.to_csv('bs_devoluciones_1.csv', index=False)
bs_devoluciones_2.to_csv('bs_devoluciones_2.csv', index=False)
bs_devoluciones_3.to_csv('bs_devoluciones_3.csv', index=False)
bs_devoluciones_4.to_csv('bs_devoluciones_4.csv', index=False)
bs_devoluciones_5.to_csv('bs_devoluciones_5.csv', index=False)

"""##Creación Base SQL - en servidor"""

###SQL para bs_devoluciones_1.csv:
CREATE TABLE bs_devoluciones_1 (
  id_ord_prod VARCHAR(255),
  idOrden INT,
  idProducto INT,
  cantidadDevuelta INT,
  fechaDevolucion VARCHAR(255)
);

###SQL para bs_devoluciones_2.csv:
CREATE TABLE bs_devoluciones_2 (
  id_ord_prod VARCHAR(255),
  id_motdev INT
);

###SQL para bs_devoluciones_3.csv:
CREATE TABLE bs_devoluciones_3 (
  id_motdev INT,
  motivoDevolucion VARCHAR(255)
);

###SQL para bs_devoluciones_4.csv:
CREATE TABLE bs_devoluciones_4 (
  id_ord_prod VARCHAR(255),
  id_resol INT
);

###SQL para bs_devoluciones_5.csv:
CREATE TABLE bs_devoluciones_5 (
  id_resol INT,
  resolucion VARCHAR(255)
);

"""##Carga SQL"""

# Conexión a la DDBB
from sqlalchemy import create_engine

USERNAME = "root"
PASSWORD = ""
BBDD = "supermercado"
PORT = "3306"  # Puerto por defecto para MySQL
SERVICE = "localhost"

# Lista de archivos CSV
csv_files = ["bs_devoluciones_1.csv", "bs_devoluciones_2.csv", "bs_devoluciones_3.csv", "bs_devoluciones_4.csv", "bs_devoluciones_5.csv"]

if __name__ == "__main__":
    # Creación del motor de conexión
    engine = create_engine(f'mysql+mysqlconnector://{USERNAME}:{PASSWORD}@{SERVICE}:{PORT}/{BBDD}', echo=False)

    # Cargar los CSVs en las tablas
    for csv_file in csv_files:
        table_name = csv_file.split(".")[0]
        df = pd.read_csv(csv_file)
        df.to_sql(table_name, engine, index=False, if_exists='replace')
        print(f"Datos cargados en la tabla {table_name}")